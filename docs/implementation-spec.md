# Agent-Based Social Dynamics Modeling Framework
## Python Implementation Specification v3.0

## Overview

This framework implements a psychology-grounded agent-based model for studying social dynamics, where each agent's personality, background, and biography are generated by Large Language Models. The system simulates how opinions evolve through natural conversations between psychologically consistent agents.

The entire implementation is in Python, designed to run as a standalone simulation engine without web services. All agent initialization leverages LLMs to ensure rich, consistent personalities and realistic biographical narratives.

## Core Architecture

```python
# Main components structure
social_dynamics_framework/
├── agents/
│   ├── __init__.py
│   ├── profile.py          # Agent data structures
│   ├── generator.py        # LLM-based agent generation
│   └── personality.py      # Personality-behavior mappings
├── interactions/
│   ├── __init__.py
│   ├── orchestrator.py     # Conversation management
│   ├── planner.py         # Pre-interaction planning
│   └── updater.py         # Post-interaction state updates
├── llm/
│   ├── __init__.py
│   ├── client.py          # LLM interface wrapper
│   └── prompts.py         # Prompt templates
├── simulation/
│   ├── __init__.py
│   ├── engine.py          # Main simulation loop
│   └── analyzer.py        # Results analysis
└── config.py              # Configuration settings
```

## Agent Model Definition

```python
from dataclasses import dataclass, field
from typing import Dict, List, Tuple
from datetime import datetime
import uuid

@dataclass
class PersonalityTraits:
    """HEXACO personality model with behavioral implications"""
    honesty_humility: int      # 0-100: Sincerity, fairness, modesty
    emotionality: int          # 0-100: Emotional reactivity, anxiety
    extraversion: int          # 0-100: Sociability, energy, boldness  
    agreeableness: int         # 0-100: Patience, tolerance, gentleness
    conscientiousness: int     # 0-100: Organization, diligence, perfectionism
    openness: int             # 0-100: Curiosity, creativity, unconventionality

@dataclass
class Background:
    """Stable demographic and life history factors"""
    age: int
    occupation: str
    education_level: str      # high_school, bachelors, masters, phd
    education_field: str      # e.g., "computer science", "literature"
    socioeconomic_tags: List[str]  # e.g., ["middle-class", "suburban"]
    relationship_tags: List[str]    # e.g., ["married", "parent-of-two"]
    cultural_tags: List[str]        # e.g., ["progressive", "religious"]

@dataclass
class EmotionalBaseline:
    """Stable emotional tendencies"""
    dispositional_affect: int    # -50 to +50: General mood tendency
    stress_tolerance: int        # 0-100: Resilience to stressors
    social_confidence: int       # 0-100: Comfort in social situations
    self_efficacy: int          # 0-100: Belief in own capabilities

@dataclass
class EmotionalState:
    """Current dynamic emotional state"""
    arousal: int = 50           # 0-100: Calm to excited
    valence: int = 0            # -50 to +50: Negative to positive
    anxiety: int = 25           # 0-100: Current worry level
    confidence: int = 50        # 0-100: Current self-assurance
    social_energy: int = 50     # 0-100: Desire for interaction
    cognitive_load: int = 25    # 0-100: Mental fatigue

@dataclass
class Opinion:
    """Opinion on a specific topic"""
    position: int              # -100 to +100: Topic-specific scale
    certainty: int             # 0-100: Confidence in position
    importance: int            # 0-100: Personal relevance
    knowledge: int             # 0-100: Perceived expertise
    emotional_charge: int      # 0-100: Emotional investment

@dataclass
class Agent:
    """Complete agent profile"""
    # Unique identifier
    id: str = field(default_factory=lambda: str(uuid.uuid4()))
    
    # Stable traits (immutable after creation)
    name: str = ""
    personality: PersonalityTraits = field(default_factory=PersonalityTraits)
    background: Background = field(default_factory=Background)
    emotional_baseline: EmotionalBaseline = field(default_factory=EmotionalBaseline)
    biography: str = ""
    
    # Dynamic state
    emotional_state: EmotionalState = field(default_factory=EmotionalState)
    opinions: Dict[str, Opinion] = field(default_factory=dict)
    
    # Metadata
    created_at: datetime = field(default_factory=datetime.now)
    last_interaction: datetime = None
```

## Personality-Behavior Ontology

The framework implements a systematic mapping between personality traits and behavioral tendencies. This ontology guides how agents behave in conversations and respond to social situations.

```python
class PersonalityBehaviorOntology:
    """Defines how HEXACO traits influence agent behavior"""
    
    # Conversation style mappings
    CONVERSATION_PATTERNS = {
        'honesty_humility': {
            'high': {
                'communication_style': 'straightforward, sincere',
                'topic_approach': 'factual, avoids exaggeration',
                'conflict_style': 'seeks fair resolution',
                'persuasion_ethics': 'avoids manipulation'
            },
            'low': {
                'communication_style': 'strategic, may embellish',
                'topic_approach': 'focuses on personal gain',
                'conflict_style': 'winning-oriented',
                'persuasion_ethics': 'ends justify means'
            }
        },
        'emotionality': {
            'high': {
                'stress_response': 'easily overwhelmed, seeks support',
                'empathy_expression': 'highly responsive to others emotions',
                'vulnerability': 'openly shares fears and concerns',
                'decision_style': 'weighs emotional consequences heavily'
            },
            'low': {
                'stress_response': 'remains calm under pressure',
                'empathy_expression': 'less affected by others emotions',
                'vulnerability': 'rarely shares personal concerns',
                'decision_style': 'logic-focused, pragmatic'
            }
        },
        'extraversion': {
            'high': {
                'interaction_energy': 'seeks out conversations',
                'speaking_ratio': 'dominates conversation time',
                'topic_breadth': 'introduces many topics',
                'social_fatigue': 'energized by interaction'
            },
            'low': {
                'interaction_energy': 'selective engagement',
                'speaking_ratio': 'listens more than speaks',
                'topic_breadth': 'focuses on few deep topics',
                'social_fatigue': 'drained by extended interaction'
            }
        },
        'agreeableness': {
            'high': {
                'conflict_avoidance': 'seeks harmony, compromises',
                'criticism_style': 'gentle, constructive',
                'cooperation': 'looks for win-win solutions',
                'trust_tendency': 'assumes good intentions'
            },
            'low': {
                'conflict_avoidance': 'comfortable with disagreement',
                'criticism_style': 'direct, potentially harsh',
                'cooperation': 'prioritizes personal goals',
                'trust_tendency': 'skeptical of others motives'
            }
        },
        'conscientiousness': {
            'high': {
                'argument_structure': 'organized, systematic',
                'fact_checking': 'careful about accuracy',
                'commitment': 'follows through on statements',
                'time_awareness': 'respects conversation bounds'
            },
            'low': {
                'argument_structure': 'spontaneous, may ramble',
                'fact_checking': 'makes broad generalizations',
                'commitment': 'flexible with promises',
                'time_awareness': 'loses track of time'
            }
        },
        'openness': {
            'high': {
                'idea_receptivity': 'eager to explore new concepts',
                'opinion_flexibility': 'willing to change views',
                'curiosity': 'asks probing questions',
                'abstraction': 'enjoys theoretical discussions'
            },
            'low': {
                'idea_receptivity': 'prefers familiar concepts',
                'opinion_flexibility': 'maintains established views',
                'curiosity': 'focuses on practical matters',
                'abstraction': 'prefers concrete examples'
            }
        }
    }
    
    # Opinion change receptivity modifiers
    INFLUENCE_MODIFIERS = {
        'honesty_humility': {
            'source_credibility_weight': lambda h: 0.5 + (h/100) * 0.5,  # High H values credibility more
            'emotional_appeal_resistance': lambda h: h/100  # High H resists emotional manipulation
        },
        'emotionality': {
            'emotional_contagion': lambda e: e/100,  # High E catches others' emotions
            'stress_opinion_volatility': lambda e: 0.5 + (e/100) * 0.5  # High E changes opinions under stress
        },
        'extraversion': {
            'social_proof_sensitivity': lambda e: 0.3 + (e/100) * 0.4,  # High E influenced by group
            'conversation_engagement': lambda e: 0.5 + (e/100) * 0.5  # High E more engaged
        },
        'agreeableness': {
            'conflict_opinion_shift': lambda a: a/100,  # High A shifts to reduce conflict
            'empathy_driven_change': lambda a: 0.3 + (a/100) * 0.5  # High A influenced by others' needs
        },
        'conscientiousness': {
            'evidence_requirement': lambda c: 0.3 + (c/100) * 0.7,  # High C needs strong evidence
            'consistency_pressure': lambda c: c/100  # High C resists contradicting past positions
        },
        'openness': {
            'novelty_bonus': lambda o: (o/100) * 0.5,  # High O gives weight to new ideas
            'certainty_flexibility': lambda o: 1 - (o/100) * 0.5  # High O has lower certainty barriers
        }
    }
    
    @staticmethod
    def get_conversation_intent_probability(personality: PersonalityTraits) -> Dict[str, float]:
        """Calculate probability of each conversation intent based on personality"""
        return {
            'learn': 0.2 + (personality.openness/100) * 0.4 + (100-personality.emotionality)/100 * 0.2,
            'persuade': 0.1 + (personality.extraversion/100) * 0.3 + (100-personality.agreeableness)/100 * 0.2,
            'validate': 0.1 + (personality.emotionality/100) * 0.4 + (100-personality.openness)/100 * 0.2,
            'bond': 0.2 + (personality.agreeableness/100) * 0.4 + (personality.extraversion/100) * 0.2,
            'debate': 0.1 + (personality.openness/100) * 0.3 + (100-personality.agreeableness)/100 * 0.2,
            'explore': 0.2 + (personality.openness/100) * 0.3 + (personality.conscientiousness/100) * 0.1
        }
```

## LLM-Based Agent Generation

All agent initialization uses carefully crafted prompts to ensure psychological consistency and rich biographical details.

```python
class AgentGenerator:
    """Generates complete agent profiles using LLM"""
    
    def __init__(self, llm_client):
        self.llm = llm_client
        self.ontology = PersonalityBehaviorOntology()
    
    def generate_agent(self, constraints: Dict = None) -> Agent:
        """Generate a complete agent profile"""
        # Step 1: Generate personality traits
        personality = self._generate_personality(constraints)
        
        # Step 2: Generate consistent background
        background = self._generate_background(personality, constraints)
        
        # Step 3: Derive emotional baseline
        emotional_baseline = self._generate_emotional_baseline(personality, background)
        
        # Step 4: Generate biography
        biography = self._generate_biography(personality, background, emotional_baseline)
        
        # Step 5: Initialize opinions for pre-selected topics
        opinions = self._initialize_opinions(personality, background, biography, constraints)
        
        # Step 6: Set initial emotional state
        emotional_state = self._set_initial_emotional_state(emotional_baseline, background)
        
        return Agent(
            name=background.name,
            personality=personality,
            background=background,
            emotional_baseline=emotional_baseline,
            biography=biography,
            emotional_state=emotional_state,
            opinions=opinions
        )
    
    def _generate_personality(self, constraints: Dict) -> PersonalityTraits:
        """Generate HEXACO traits using LLM"""
        
        prompt = """Generate a psychologically realistic personality profile using the HEXACO model.
        
Each trait should be a value from 0-100 where:
- 0-20: Very low
- 21-40: Low  
- 41-60: Average
- 61-80: High
- 81-100: Very high

The traits are:
1. Honesty-Humility: Sincerity, fairness, greed avoidance, modesty
2. Emotionality: Fearfulness, anxiety, dependence, sentimentality  
3. Extraversion: Social self-esteem, social boldness, sociability, liveliness
4. Agreeableness: Forgiveness, gentleness, flexibility, patience
5. Conscientiousness: Organization, diligence, perfectionism, prudence
6. Openness: Aesthetic appreciation, inquisitiveness, creativity, unconventionality

Generate a coherent personality avoiding impossible combinations (e.g., very high extraversion with very high anxiety is uncommon).

{constraints}

Respond with ONLY a JSON object in this exact format:
{
  "honesty_humility": <int>,
  "emotionality": <int>,
  "extraversion": <int>,
  "agreeableness": <int>,
  "conscientiousness": <int>,
  "openness": <int>
}"""
        
        constraint_text = ""
        if constraints and 'personality_bias' in constraints:
            constraint_text = f"Bias the personality toward: {constraints['personality_bias']}"
            
        response = self.llm.generate(prompt.format(constraints=constraint_text))
        traits_dict = json.loads(response)
        
        return PersonalityTraits(**traits_dict)
    
    def _generate_background(self, personality: PersonalityTraits, constraints: Dict) -> Background:
        """Generate background consistent with personality"""
        
        prompt = f"""Given the following personality profile, generate a realistic demographic background.

Personality Profile:
- Honesty-Humility: {personality.honesty_humility}/100
- Emotionality: {personality.emotionality}/100  
- Extraversion: {personality.extraversion}/100
- Agreeableness: {personality.agreeableness}/100
- Conscientiousness: {personality.conscientiousness}/100
- Openness: {personality.openness}/100

Create a background that aligns with this personality. For example:
- High openness might correlate with creative fields or higher education
- High conscientiousness might lead to structured careers
- High extraversion might lead to social occupations

Include:
1. Full name (realistic for the demographic)
2. Age (18-80)
3. Occupation (specific role and seniority level)
4. Education level and field
5. 2-4 socioeconomic tags (e.g., "middle-class", "urban", "immigrant-family")
6. 2-3 relationship tags (e.g., "married", "divorced", "parent-of-one")
7. 2-3 cultural tags (e.g., "progressive", "traditional", "secular")

{constraints}

Respond with ONLY a JSON object matching this structure:
{{
  "name": "<full name>",
  "age": <int>,
  "occupation": "<specific role>",
  "education_level": "<high_school|bachelors|masters|phd>",
  "education_field": "<field of study>",
  "socioeconomic_tags": ["tag1", "tag2", ...],
  "relationship_tags": ["tag1", "tag2", ...],
  "cultural_tags": ["tag1", "tag2", ...]
}}"""

        constraint_text = ""
        if constraints and 'demographics' in constraints:
            constraint_text = f"Additional constraints: {constraints['demographics']}"
            
        response = self.llm.generate(prompt.format(constraints=constraint_text))
        background_dict = json.loads(response)
        
        return Background(**background_dict)
    
    def _generate_biography(self, personality: PersonalityTraits, 
                          background: Background, 
                          emotional_baseline: EmotionalBaseline) -> str:
        """Generate rich biographical narrative"""
        
        prompt = f"""Write a detailed biographical narrative for the following person.

PROFILE:
Name: {background.name}
Age: {background.age}
Occupation: {background.occupation}
Education: {background.education_level} in {background.education_field}

PERSONALITY (HEXACO):
- Honesty-Humility: {personality.honesty_humility}/100 
- Emotionality: {personality.emotionality}/100
- Extraversion: {personality.extraversion}/100
- Agreeableness: {personality.agreeableness}/100
- Conscientiousness: {personality.conscientiousness}/100
- Openness: {personality.openness}/100

BACKGROUND CONTEXT:
- Socioeconomic: {', '.join(background.socioeconomic_tags)}
- Relationships: {', '.join(background.relationship_tags)}
- Cultural: {', '.join(background.cultural_tags)}

EMOTIONAL TENDENCIES:
- General mood: {"positive" if emotional_baseline.dispositional_affect > 0 else "negative"} ({abs(emotional_baseline.dispositional_affect)}/50)
- Stress tolerance: {emotional_baseline.stress_tolerance}/100
- Social confidence: {emotional_baseline.social_confidence}/100
- Self-efficacy: {emotional_baseline.self_efficacy}/100

Write a 800-1200 word biography that:
1. Explains how their personality developed through life experiences
2. Describes their typical behavior patterns and social style
3. Includes specific formative experiences that shaped their worldview
4. Details their career path and why it suits their personality
5. Explains their relationship patterns and social circles
6. Describes their hobbies, interests, and values
7. Mentions how they typically handle stress and conflict
8. Includes quirks and distinguishing characteristics

Make the biography feel authentic and three-dimensional. Show how all these elements interconnect to create a coherent person."""

        biography = self.llm.generate(prompt)
        return biography
    
    def _initialize_opinions(self, personality: PersonalityTraits,
                           background: Background,
                           biography: str,
                           constraints: Dict) -> Dict[str, Opinion]:
        """Initialize opinions on pre-selected topics"""
        
        topics = constraints.get('topics', ['climate_change', 'remote_work', 'universal_healthcare'])
        opinions = {}
        
        for topic in topics:
            prompt = f"""Based on this person's profile, determine their opinion on {topic}.

PROFILE SUMMARY:
Name: {background.name}
Occupation: {background.occupation}
Education: {background.education_level} in {background.education_field}
Cultural background: {', '.join(background.cultural_tags)}

PERSONALITY HIGHLIGHTS:
- Openness: {personality.openness}/100 (affects receptivity to change)
- Conscientiousness: {personality.conscientiousness}/100 (affects need for evidence)
- Agreeableness: {personality.agreeableness}/100 (affects concern for others)

BIOGRAPHY EXCERPT:
{biography[:500]}...

For the topic "{topic}", determine:
1. Position (-100 to +100): Their stance on the issue
2. Certainty (0-100): How sure they are of their position
3. Importance (0-100): How much this topic matters to them personally
4. Knowledge (0-100): How informed they believe themselves to be
5. Emotional charge (0-100): How emotionally invested they are

Consider how their background and personality would realistically shape their views.

Respond with ONLY a JSON object:
{{
  "position": <int between -100 and 100>,
  "certainty": <int between 0 and 100>,
  "importance": <int between 0 and 100>,
  "knowledge": <int between 0 and 100>,
  "emotional_charge": <int between 0 and 100>
}}"""

            response = self.llm.generate(prompt)
            opinion_dict = json.loads(response)
            opinions[topic] = Opinion(**opinion_dict)
            
        return opinions
```

## Interaction System

The interaction system orchestrates conversations between agents, managing the flow from planning through execution to state updates.

```python
class ConversationOrchestrator:
    """Manages agent conversations"""
    
    def __init__(self, llm_client):
        self.llm = llm_client
        self.ontology = PersonalityBehaviorOntology()
    
    def conduct_conversation(self, agent1: Agent, agent2: Agent, 
                           context: Dict = None) -> 'Conversation':
        """Execute a complete conversation between two agents"""
        
        # Plan the interaction
        plan = self._plan_interaction(agent1, agent2, context)
        
        # Execute the conversation
        transcript = self._execute_conversation(agent1, agent2, plan)
        
        # Analyze results
        analysis = self._analyze_conversation(transcript, agent1, agent2)
        
        # Update agent states
        updates = self._update_states(agent1, agent2, analysis)
        
        return Conversation(
            participants=[agent1.id, agent2.id],
            plan=plan,
            transcript=transcript,
            analysis=analysis,
            state_changes=updates,
            timestamp=datetime.now()
        )
    
    def _plan_interaction(self, agent1: Agent, agent2: Agent, 
                         context: Dict) -> 'InteractionPlan':
        """Determine topics and intents for the conversation"""
        
        # Find overlapping topics of interest
        shared_topics = set(agent1.opinions.keys()) & set(agent2.opinions.keys())
        
        # Select topics based on importance and emotional charge
        topic_scores = {}
        for topic in shared_topics:
            score = (
                agent1.opinions[topic].importance + agent2.opinions[topic].importance +
                agent1.opinions[topic].emotional_charge + agent2.opinions[topic].emotional_charge
            ) / 4
            topic_scores[topic] = score
        
        # Select top topics
        selected_topics = sorted(topic_scores.items(), key=lambda x: x[1], reverse=True)[:3]
        
        # Determine intents based on personality
        intent1 = self._determine_intent(agent1, agent2, [t[0] for t in selected_topics])
        intent2 = self._determine_intent(agent2, agent1, [t[0] for t in selected_topics])
        
        return InteractionPlan(
            topics=[t[0] for t in selected_topics],
            intents={agent1.id: intent1, agent2.id: intent2},
            context=context or {}
        )
    
    def _execute_conversation(self, agent1: Agent, agent2: Agent,
                            plan: 'InteractionPlan') -> List[Dict]:
        """Run the actual conversation using LLM"""
        
        # Create conversation prompts for each agent
        prompt1 = self._create_conversation_prompt(agent1, plan.intents[agent1.id], plan)
        prompt2 = self._create_conversation_prompt(agent2, plan.intents[agent2.id], plan)
        
        transcript = []
        conversation_context = []
        
        # Conversation loop
        for turn in range(10):  # Maximum 10 turns each
            # Agent 1 speaks
            agent1_message = self.llm.generate(
                prompt1 + "\n\nConversation so far:\n" + 
                "\n".join([f"{m['speaker']}: {m['content']}" for m in conversation_context]) +
                f"\n\nYour turn to speak as {agent1.name}:"
            )
            
            transcript.append({
                'speaker': agent1.name,
                'speaker_id': agent1.id,
                'content': agent1_message,
                'turn': turn * 2
            })
            conversation_context.append({'speaker': agent1.name, 'content': agent1_message})
            
            # Check for natural conclusion
            if self._is_conversation_complete(agent1_message, transcript):
                break
            
            # Agent 2 responds
            agent2_message = self.llm.generate(
                prompt2 + "\n\nConversation so far:\n" + 
                "\n".join([f"{m['speaker']}: {m['content']}" for m in conversation_context]) +
                f"\n\nYour turn to speak as {agent2.name}:"
            )
            
            transcript.append({
                'speaker': agent2.name,
                'speaker_id': agent2.id,
                'content': agent2_message,
                'turn': turn * 2 + 1
            })
            conversation_context.append({'speaker': agent2.name, 'content': agent2_message})
            
            if self._is_conversation_complete(agent2_message, transcript):
                break
                
        return transcript
    
    def _create_conversation_prompt(self, agent: Agent, intent: str, 
                                  plan: 'InteractionPlan') -> str:
        """Create the LLM prompt for an agent in conversation"""
        
        # Get behavioral guidance from ontology
        behavior_guide = self._generate_behavior_guide(agent.personality)
        
        prompt = f"""You are {agent.name}, a {agent.background.age}-year-old {agent.background.occupation}.

BIOGRAPHY:
{agent.biography}

YOUR PERSONALITY:
{self._describe_personality(agent.personality)}

CURRENT EMOTIONAL STATE:
- Energy: {agent.emotional_state.arousal}/100
- Mood: {agent.emotional_state.valence} (-50 to +50)
- Anxiety: {agent.emotional_state.anxiety}/100
- Confidence: {agent.emotional_state.confidence}/100

YOUR OPINIONS ON TODAY'S TOPICS:
{self._describe_opinions(agent.opinions, plan.topics)}

CONVERSATION APPROACH:
Your intent is to {intent}. {self._describe_intent(intent)}

BEHAVIORAL GUIDANCE:
{behavior_guide}

Engage naturally in conversation. Be authentic to your personality and current state. Let your traits guide how you speak, what you focus on, and how you respond to others."""
        
        return prompt
    
    def _update_states(self, agent1: Agent, agent2: Agent,
                      analysis: 'ConversationAnalysis') -> Dict:
        """Update agent states based on conversation outcomes"""
        
        updates = {
            agent1.id: self._calculate_state_changes(agent1, agent2, analysis.agent1_perspective),
            agent2.id: self._calculate_state_changes(agent2, agent1, analysis.agent2_perspective)
        }
        
        # Apply opinion updates
        for topic, changes in updates[agent1.id]['opinion_changes'].items():
            for field, delta in changes.items():
                current_value = getattr(agent1.opinions[topic], field)
                new_value = max(0, min(100, current_value + delta))
                setattr(agent1.opinions[topic], field, new_value)
        
        # Apply emotional updates
        for field, delta in updates[agent1.id]['emotion_changes'].items():
            current_value = getattr(agent1.emotional_state, field)
            new_value = max(-50 if field == 'valence' else 0, 
                          min(50 if field == 'valence' else 100, current_value + delta))
            setattr(agent1.emotional_state, field, new_value)
        
        # Same for agent2
        for topic, changes in updates[agent2.id]['opinion_changes'].items():
            for field, delta in changes.items():
                current_value = getattr(agent2.opinions[topic], field)
                new_value = max(0, min(100, current_value + delta))
                setattr(agent2.opinions[topic], field, new_value)
        
        for field, delta in updates[agent2.id]['emotion_changes'].items():
            current_value = getattr(agent2.emotional_state, field)
            new_value = max(-50 if field == 'valence' else 0,
                          min(50 if field == 'valence' else 100, current_value + delta))
            setattr(agent2.emotional_state, field, new_value)
        
        return updates
    
    def _calculate_state_changes(self, agent: Agent, partner: Agent,
                               perspective: 'AgentPerspective') -> Dict:
        """Calculate how an agent's state should change"""
        
        changes = {
            'opinion_changes': {},
            'emotion_changes': {}
        }
        
        # Opinion changes based on influence factors
        for topic in perspective.topics_discussed:
            if topic not in agent.opinions:
                continue
                
            # Base influence calculation
            influence = self._calculate_influence(
                agent, partner, topic, 
                perspective.arguments_encountered[topic]
            )
            
            if abs(influence['position_delta']) > 2:  # Threshold for change
                changes['opinion_changes'][topic] = {
                    'position': influence['position_delta'],
                    'certainty': influence['certainty_delta'],
                    'importance': influence['importance_delta']
                }
        
        # Emotional state changes
        emotion_deltas = self._calculate_emotional_impact(
            agent,
            perspective.interaction_quality,
            perspective.validation_received,
            perspective.conflict_level
        )
        
        changes['emotion_changes'] = emotion_deltas
        
        return changes
    
    def _calculate_influence(self, agent: Agent, partner: Agent,
                           topic: str, arguments: List[str]) -> Dict:
        """Calculate opinion change based on personality and arguments"""
        
        # Get personality-based modifiers from ontology
        modifiers = self.ontology.INFLUENCE_MODIFIERS
        
        # Source credibility based on perceived expertise
        credibility = self._assess_credibility(agent, partner, topic)
        
        # Personality-moderated receptivity
        openness_mod = modifiers['openness']['novelty_bonus'](agent.personality.openness)
        certainty_barrier = modifiers['openness']['certainty_flexibility'](agent.personality.openness)
        evidence_need = modifiers['conscientiousness']['evidence_requirement'](agent.personality.conscientiousness)
        
        # Analyze argument strength using LLM
        argument_quality = self._evaluate_argument_quality(arguments, agent)
        
        # Calculate base influence
        base_influence = credibility * argument_quality * (1 + openness_mod)
        
        # Apply certainty resistance
        certainty_resistance = (agent.opinions[topic].certainty / 100) * certainty_barrier
        effective_influence = base_influence * (1 - certainty_resistance)
        
        # Calculate position change
        position_diff = partner.opinions[topic].position - agent.opinions[topic].position
        position_delta = position_diff * effective_influence * 0.1  # 10% max change
        
        # Certainty changes based on argument quality
        certainty_delta = 5 if argument_quality > evidence_need else -3
        
        # Importance might increase if topic was engaging
        importance_delta = 3 if abs(position_delta) > 5 else 0
        
        return {
            'position_delta': position_delta,
            'certainty_delta': certainty_delta,
            'importance_delta': importance_delta,
            'influence_strength': effective_influence
        }
```

## Simulation Engine

The main simulation engine coordinates multiple agents and tracks emergent social dynamics.

```python
class SimulationEngine:
    """Main simulation coordinator"""
    
    def __init__(self, llm_client):
        self.llm_client = llm_client
        self.generator = AgentGenerator(llm_client)
        self.orchestrator = ConversationOrchestrator(llm_client)
        self.agents = {}
        self.conversations = []
        self.metrics = []
    
    def initialize_population(self, size: int, topics: List[str], 
                            demographics: Dict = None) -> None:
        """Create initial agent population"""
        
        print(f"Generating {size} agents...")
        
        for i in range(size):
            constraints = {
                'topics': topics,
                'demographics': demographics
            }
            
            # Add some variety in personality distributions
            if i % 5 == 0:
                constraints['personality_bias'] = 'high openness'
            elif i % 5 == 1:
                constraints['personality_bias'] = 'high conscientiousness'
            elif i % 5 == 2:
                constraints['personality_bias'] = 'high agreeableness'
            
            agent = self.generator.generate_agent(constraints)
            self.agents[agent.id] = agent
            
            print(f"Created agent {i+1}/{size}: {agent.name}")
    
    def run_interaction_round(self, interaction_probability: float = 0.1,
                            homophily_bias: float = 0.5) -> None:
        """Run one round of interactions between agents"""
        
        agent_list = list(self.agents.values())
        interactions_this_round = []
        
        # Determine which agents will interact
        for i, agent1 in enumerate(agent_list):
            for agent2 in agent_list[i+1:]:
                # Base probability of interaction
                if random.random() > interaction_probability:
                    continue
                
                # Apply homophily bias (similar agents more likely to interact)
                similarity = self._calculate_similarity(agent1, agent2)
                interaction_chance = interaction_probability * (1 + homophily_bias * similarity)
                
                if random.random() < interaction_chance:
                    # Conduct conversation
                    conversation = self.orchestrator.conduct_conversation(agent1, agent2)
                    self.conversations.append(conversation)
                    interactions_this_round.append((agent1.name, agent2.name))
                    
                    # Update last interaction time
                    agent1.last_interaction = datetime.now()
                    agent2.last_interaction = datetime.now()
        
        print(f"Completed {len(interactions_this_round)} interactions this round")
        
        # Calculate and store metrics
        round_metrics = self.calculate_population_metrics()
        self.metrics.append(round_metrics)
    
    def run_simulation(self, rounds: int, **kwargs) -> None:
        """Run complete simulation"""
        
        print(f"Starting simulation with {len(self.agents)} agents for {rounds} rounds")
        
        for round_num in range(rounds):
            print(f"\n--- Round {round_num + 1}/{rounds} ---")
            
            self.run_interaction_round(**kwargs)
            
            # Print summary metrics
            metrics = self.metrics[-1]
            print(f"Opinion polarization: {metrics['polarization']:.3f}")
            print(f"Average certainty: {metrics['avg_certainty']:.3f}")
            print(f"Consensus level: {metrics['consensus']:.3f}")
    
    def calculate_population_metrics(self) -> Dict:
        """Calculate population-level metrics"""
        
        metrics = {}
        
        # Get all topics
        topics = list(next(iter(self.agents.values())).opinions.keys())
        
        for topic in topics:
            positions = [agent.opinions[topic].position for agent in self.agents.values()]
            certainties = [agent.opinions[topic].certainty for agent in self.agents.values()]
            
            # Polarization (bimodality of distribution)
            metrics[f'{topic}_polarization'] = self._calculate_polarization(positions)
            
            # Average certainty
            metrics[f'{topic}_avg_certainty'] = np.mean(certainties)
            
            # Consensus (inverse of standard deviation)
            metrics[f'{topic}_consensus'] = 1 / (1 + np.std(positions) / 100)
        
        # Overall metrics
        metrics['polarization'] = np.mean([v for k, v in metrics.items() if 'polarization' in k])
        metrics['avg_certainty'] = np.mean([v for k, v in metrics.items() if 'avg_certainty' in k])
        metrics['consensus'] = np.mean([v for k, v in metrics.items() if 'consensus' in k])
        
        return metrics
    
    def _calculate_polarization(self, positions: List[float]) -> float:
        """Calculate polarization as bimodality of opinion distribution"""
        
        # Simple measure: distance between peaks if bimodal
        hist, bins = np.histogram(positions, bins=20)
        
        # Find peaks
        peaks = []
        for i in range(1, len(hist) - 1):
            if hist[i] > hist[i-1] and hist[i] > hist[i+1]:
                peaks.append(bins[i])
        
        if len(peaks) >= 2:
            # Distance between two highest peaks
            peak_distance = abs(peaks[0] - peaks[1]) / 200  # Normalize
            return peak_distance
        else:
            return 0.0
    
    def _calculate_similarity(self, agent1: Agent, agent2: Agent) -> float:
        """Calculate similarity between agents for homophily"""
        
        # Personality similarity
        personality_diff = sum([
            abs(getattr(agent1.personality, trait) - getattr(agent2.personality, trait))
            for trait in ['honesty_humility', 'emotionality', 'extraversion',
                         'agreeableness', 'conscientiousness', 'openness']
        ]) / 600  # Normalize
        
        personality_similarity = 1 - personality_diff
        
        # Background similarity
        background_similarity = 0
        if agent1.background.education_level == agent2.background.education_level:
            background_similarity += 0.25
        
        # Shared tags
        shared_cultural = len(set(agent1.background.cultural_tags) & 
                            set(agent2.background.cultural_tags))
        background_similarity += shared_cultural * 0.25
        
        return (personality_similarity + background_similarity) / 2
```

## Usage Example

Here's how to use the complete framework:

```python
import json
from typing import Dict, List
import numpy as np
import random
from datetime import datetime

# Initialize the simulation
def run_opinion_dynamics_simulation():
    """Example simulation studying opinion polarization"""
    
    # Setup LLM client (using OpenAI as example)
    from openai import OpenAI
    client = OpenAI()
    
    class LLMClient:
        def generate(self, prompt: str) -> str:
            response = client.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7
            )
            return response.choices[0].message.content
    
    llm_client = LLMClient()
    
    # Initialize simulation engine
    sim = SimulationEngine(llm_client)
    
    # Define topics for the simulation
    topics = [
        'climate_change',      # -100: denial to +100: urgent action
        'wealth_inequality',   # -100: meritocracy to +100: redistribution  
        'ai_regulation'        # -100: no regulation to +100: strict control
    ]
    
    # Create diverse population
    demographics = {
        'age_range': (25, 65),
        'education_distribution': {
            'high_school': 0.3,
            'bachelors': 0.4,
            'masters': 0.2,
            'phd': 0.1
        }
    }
    
    # Initialize 50 agents
    sim.initialize_population(
        size=50,
        topics=topics,
        demographics=demographics
    )
    
    # Run simulation for 20 rounds
    sim.run_simulation(
        rounds=20,
        interaction_probability=0.15,  # 15% chance of interaction per pair
        homophily_bias=0.6  # Moderate tendency to interact with similar others
    )
    
    # Analyze results
    print("\n=== SIMULATION COMPLETE ===")
    print(f"Total conversations: {len(sim.conversations)}")
    
    # Plot opinion evolution
    plot_opinion_evolution(sim)
    
    # Identify influential agents
    influential = identify_influencers(sim)
    print(f"\nMost influential agents: {influential}")
    
    # Export data for further analysis
    export_simulation_data(sim, "opinion_dynamics_results.json")

def plot_opinion_evolution(sim: SimulationEngine):
    """Visualize how opinions changed over time"""
    
    import matplotlib.pyplot as plt
    
    # Track opinion changes per round
    topics = list(next(iter(sim.agents.values())).opinions.keys())
    
    fig, axes = plt.subplots(1, len(topics), figsize=(15, 5))
    
    for idx, topic in enumerate(topics):
        ax = axes[idx]
        
        # Get initial and final distributions
        initial_positions = [agent.opinions[topic].position 
                           for agent in sim.agents.values()]
        
        # Note: In a real implementation, you'd track positions per round
        # This is simplified for the example
        
        ax.hist(initial_positions, bins=20, alpha=0.5, label='Initial')
        ax.set_title(f'Opinion Distribution: {topic}')
        ax.set_xlabel('Position (-100 to +100)')
        ax.set_ylabel('Number of Agents')
        ax.legend()
    
    plt.tight_layout()
    plt.savefig('opinion_evolution.png')
    print("Saved opinion evolution plot to opinion_evolution.png")

def identify_influencers(sim: SimulationEngine) -> List[str]:
    """Identify agents who had the most influence on others"""
    
    influence_scores = {}
    
    for conversation in sim.conversations:
        # Sum up influence strength from state changes
        for agent_id, changes in conversation.state_changes.items():
            partner_id = [pid for pid in conversation.participants if pid != agent_id][0]
            
            if partner_id not in influence_scores:
                influence_scores[partner_id] = 0
            
            # Calculate total opinion change caused
            total_change = sum([
                abs(change.get('position', 0))
                for change in changes.get('opinion_changes', {}).values()
            ])
            
            influence_scores[partner_id] += total_change
    
    # Get top 5 influencers
    top_influencers = sorted(influence_scores.items(), 
                           key=lambda x: x[1], reverse=True)[:5]
    
    return [(sim.agents[aid].name, score) for aid, score in top_influencers]

def export_simulation_data(sim: SimulationEngine, filename: str):
    """Export simulation data for analysis"""
    
    data = {
        'metadata': {
            'num_agents': len(sim.agents),
            'num_conversations': len(sim.conversations),
            'topics': list(next(iter(sim.agents.values())).opinions.keys())
        },
        'agents': [
            {
                'id': agent.id,
                'name': agent.name,
                'personality': agent.personality.__dict__,
                'background': agent.background.__dict__,
                'final_opinions': {
                    topic: opinion.__dict__ 
                    for topic, opinion in agent.opinions.items()
                }
            }
            for agent in sim.agents.values()
        ],
        'metrics_evolution': sim.metrics
    }
    
    with open(filename, 'w') as f:
        json.dump(data, f, indent=2, default=str)
    
    print(f"Exported simulation data to {filename}")

# Run the simulation
if __name__ == "__main__":
    run_opinion_dynamics_simulation()
```

## Configuration File

```python
# config.py
"""Configuration settings for the social dynamics framework"""

# LLM Settings
LLM_MODEL = "gpt-4"  # or "claude-3", "llama-70b", etc.
LLM_TEMPERATURE = 0.7
LLM_MAX_TOKENS = 1000

# Conversation Settings
MAX_CONVERSATION_TURNS = 10
MIN_CONVERSATION_TURNS = 3
CONCLUSION_KEYWORDS = ["goodbye", "bye", "talk later", "nice talking"]

# Influence Parameters
INFLUENCE_THRESHOLD = 0.1  # Minimum influence to cause opinion change
MAX_POSITION_CHANGE = 20   # Maximum opinion shift in one conversation
CERTAINTY_DECAY_RATE = 0.05  # How much certainty decreases when challenged

# Personality Behavior Mappings
TRAIT_THRESHOLDS = {
    'low': 33,
    'medium': 66,
    'high': 100
}

# Emotional State Bounds
EMOTION_BOUNDS = {
    'arousal': (0, 100),
    'valence': (-50, 50),
    'anxiety': (0, 100),
    'confidence': (0, 100),
    'social_energy': (0, 100),
    'cognitive_load': (0, 100)
}

# Topic Definitions
STANDARD_TOPICS = {
    'climate_change': {
        'scale': (-100, 100),
        'labels': ('Climate skeptic', 'Climate activist')
    },
    'wealth_inequality': {
        'scale': (-100, 100),
        'labels': ('Pure meritocracy', 'Wealth redistribution')
    },
    'ai_regulation': {
        'scale': (-100, 100),
        'labels': ('No regulation', 'Strict control')
    },
    'remote_work': {
        'scale': (-100, 100),
        'labels': ('Office only', 'Fully remote')
    },
    'universal_healthcare': {
        'scale': (-100, 100),
        'labels': ('Private only', 'Single payer')
    }
}
```

This complete Python framework provides everything needed to run sophisticated agent-based social dynamics simulations. The personality-behavior ontology ensures agents act consistently with their traits, while LLM-based generation creates rich, believable characters. The system can model how opinions spread and change through natural conversation, providing insights into social influence, polarization, and consensus formation.

The modular design allows researchers to easily extend the framework with new personality models, interaction types, or analysis methods while maintaining the core psychological foundations that make the simulations realistic and meaningful.